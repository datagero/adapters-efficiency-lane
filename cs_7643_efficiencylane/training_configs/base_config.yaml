# Base configuration file with common settings

training_args:
  seed: 42
  logging_strategy: 'epoch'
  evaluation_strategy: 'epoch'
  overwrite_output_dir: true
  remove_unused_columns: true
  metric_for_best_model: 'eval_loss'
  output_dir: null # Predefine, to be updated by trials
  disable_tqdm: true
  save_strategy: 'no' # Too heavy for current storage, and we just need baseline results, not actually using the model
  load_best_model_at_end: false # Cannot load best model as it is not save_strategy='no'

optuna:
  n_seeds: 5
  # # v01 is maximize f1
  # direction: maximize
  # objective: f1
  ## v02 is minimize loss
  direction: minimize
  objective: loss

  # v03 is with v02, all the same, essentially making sure v02 was set correctly for all models. -> ALSO no parallelism is used.
    # v03 This is the final version for models
  # v04 is with v02 testing minimize loss with -ve sign on optuna return
  # v05 is with v02 but changing transformer search space
  # v06 is with v01 same config as v05

#TODO NOW: Make sure all the v03 models are run for 6 trials
hydra:
  run:
    dir: .
  job:
    chdir: false

base_output_dir: ./training_output
seeds: [42, 128, 9091, 746483, 8937216]